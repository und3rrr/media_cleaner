"""
Imperceptible Protected Video Generator v2.0

–ü—Ä–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è "–Ω–µ–≤–∏–¥–∏–º–æ–≥–æ" —à—É–º–∞ –≤ –≤–∏–¥–µ–æ:
- –®—É–º –Ω–∞ –∫–∞–¥—Ä–∞—Ö (adversarial noise) ‚Äî –¥–ª—è CV-–º–æ–¥–µ–ª–µ–π
- –®—É–º –Ω–∞ –∑–≤—É–∫–µ (audio masking) ‚Äî –¥–ª—è ASR-–º–æ–¥–µ–ª–µ–π

–ß–µ–ª–æ–≤–µ–∫ –ø–æ—á—Ç–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –∑–∞–º–µ—á–∞–µ—Ç, –∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å–∏–ª—å–Ω–æ –ø—É—Ç–∞—é—Ç—Å—è.
"""

import logging
import sys
import json
from pathlib import Path
from typing import Optional, Tuple, Dict
import traceback

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from torch import nn
from torchvision import models, transforms
from torchvision.models.resnet import ResNet18_Weights
from PIL import Image
import subprocess
import shutil
import librosa
import soundfile as sf
from tqdm import tqdm

# ‚îÄ‚îÄ‚îÄ‚îÄ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CONFIG = {
    "ffmpeg_path": r"C:\users\user\desktop\media_cleaner\ffmpeg\ffmpeg\bin\ffmpeg.exe",
    "epsilon_video": 0.120,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –≤ 11 —Ä–∞–∑ –¥–ª—è –±–æ–ª–µ–µ —Å–∏–ª—å–Ω–æ–≥–æ —à—É–º–∞ (–±—ã–ª–æ 0.011)
    "epsilon_multiplier_strong": 1.8,  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è —Å–∏–ª—å–Ω–µ–π—à–µ–π –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏
    "num_eot_transforms": 4,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–µ–π robustness
    "default_every_n_frames": 10,
    "high_freq_base": 17000,
    "audio_levels": {
        "–æ—á–µ–Ω—å —Å–ª–∞–±—ã–π": 0.0020,
        "—Å–ª–∞–±—ã–π": 0.0035,
        "—Å—Ä–µ–¥–Ω–∏–π": 0.0050,
        "—Å–∏–ª—å–Ω—ã–π": 0.0080
    },
    "supported_video": {'.mp4', '.mov', '.avi', '.mkv', '.webm'},
    "log_level": "INFO",
    "temp_folder_prefix": "_temp_adv_"
}

# ‚îÄ‚îÄ‚îÄ‚îÄ –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('imperceptible_protected_video.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ‚îÄ –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DEVICE = None  # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ init_device()
_model = None  # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ init_device()

def init_device(device_type: str = "auto"):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU/GPU) –∏ –º–æ–¥–µ–ª—å."""
    global DEVICE, _model
    
    if device_type == "auto":
        DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    elif device_type == "gpu":
        if torch.cuda.is_available():
            DEVICE = torch.device("cuda")
        else:
            logger.warning("GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
            DEVICE = torch.device("cpu")
    else:
        DEVICE = torch.device("cpu")
    
    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}")
    
    try:
        _model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1).to(DEVICE)
        _model.eval()
        _model.requires_grad_(False)
        logger.info("[OK] ResNet18 model loaded successfully")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ ResNet18: {e}")
        _model = None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
init_device("auto")

_preprocess = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])


# ‚îÄ‚îÄ‚îÄ‚îÄ –§–£–ù–ö–¶–ò–ò –ü–†–û–í–ï–†–ö–ò –í–ò–î–ï–û ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def verify_video_changes(original_path: str, processed_path: str, frame_num: int = 0):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ –ø—É—Ç—ë–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤."""
    try:
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤–∏–¥–µ–æ...")
        print(f"  –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {original_path}")
        print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {processed_path}")
        
        if not Path(original_path).exists() or not Path(processed_path).exists():
            print("‚ùå –û–¥–∏–Ω –∏–ª–∏ –æ–±–∞ —Ñ–∞–π–ª–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
            return False
        
        # –û—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ
        original_cap = cv2.VideoCapture(original_path)
        processed_cap = cv2.VideoCapture(processed_path)
        
        if not original_cap.isOpened() or not processed_cap.isOpened():
            print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞—ë—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ —Ñ–∞–π–ª—ã")
            return False
        
        # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        orig_fps = original_cap.get(cv2.CAP_PROP_FPS)
        orig_count = int(original_cap.get(cv2.CAP_PROP_FRAME_COUNT))
        orig_width = int(original_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        orig_height = int(original_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        proc_fps = processed_cap.get(cv2.CAP_PROP_FPS)
        proc_count = int(processed_cap.get(cv2.CAP_PROP_FRAME_COUNT))
        proc_width = int(processed_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        proc_height = int(processed_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"\n  üìπ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ:")
        print(f"    –ò—Å—Ö–æ–¥–Ω–æ–µ:     {orig_width}x{orig_height} @ {orig_fps:.1f}fps, {orig_count} –∫–∞–¥—Ä–æ–≤")
        print(f"    –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ: {proc_width}x{proc_height} @ {proc_fps:.1f}fps, {proc_count} –∫–∞–¥—Ä–æ–≤")
        
        # –ò–∑–≤–ª–µ—á—å –∫–∞–¥—Ä
        original_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
        processed_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
        
        ret1, orig_frame = original_cap.read()
        ret2, proc_frame = processed_cap.read()
        
        if not ret1 or not ret2:
            print(f"‚ùå –ù–µ —É–¥–∞—ë—Ç—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–¥—Ä #{frame_num}")
            return False
        
        # –ü—Ä–∏–µ—Å—Ç–∏ –∫ –æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        if orig_frame.shape != proc_frame.shape:
            proc_frame = cv2.resize(proc_frame, (orig_width, orig_height))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ float –¥–ª—è —Ç–æ—á–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        orig_float = orig_frame.astype(np.float32)
        proc_float = proc_frame.astype(np.float32)
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å —Ä–∞–∑–ª–∏—á–∏—è
        diff = np.abs(orig_float - proc_float)
        mse = np.mean(diff ** 2)
        mae = np.mean(diff)
        max_diff = np.max(diff)
        
        # –ü—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π
        changed_pixels = np.sum(diff > 5)
        total_pixels = diff.shape[0] * diff.shape[1] * diff.shape[2]
        percent_changed = (changed_pixels / total_pixels) * 100
        
        print(f"\n  üîç –ê–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–∞ #{frame_num}:")
        print(f"    Mean Absolute Error (MAE): {mae:.2f}")
        print(f"    Mean Squared Error (MSE):  {mse:.2f}")
        print(f"    Max difference: {max_diff:.2f}")
        print(f"    –ò–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π: {percent_changed:.2f}%")
        
        original_cap.release()
        processed_cap.release()
        
        if mse > 100:
            print("\n‚úÖ –í–∏–¥–µ–æ –ò–ó–ú–ï–ù–ï–ù–û - –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è")
            return True
        elif mse > 1:
            print("\n‚úÖ –í–∏–¥–µ–æ –ò–ó–ú–ï–ù–ï–ù–û - –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–ª–∞–±—ã–µ —Ä–∞–∑–ª–∏—á–∏—è")
            return True
        else:
            print("\n‚ö†Ô∏è  –í–∏–¥–µ–æ –ù–ï –∏–∑–º–µ–Ω–µ–Ω–æ - —Ñ–∞–π–ª—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã")
            return False
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≤–∏–¥–µ–æ: {e}")
        return False


def verify_metadata(video_path: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é ffprobe."""
    try:
        ffprobe_path = CONFIG["ffmpeg_path"].replace("ffmpeg.exe", "ffprobe.exe")
        
        result = subprocess.run(
            [ffprobe_path, "-v", "quiet", "-print_format", "json", 
             "-show_format", video_path],
            capture_output=True, text=True, timeout=10
        )
        
        data = json.loads(result.stdout)
        tags = data.get("format", {}).get("tags", {})
        
        print(f"\n  üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–∞:")
        if tags:
            print(f"    ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
            for key, value in list(tags.items())[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                print(f"      {key}: {value}")
            return False
        else:
            print(f"    ‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã (–ø—É—Å—Ç–æ)")
            return True
    
    except Exception as e:
        logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
        return False


# ‚îÄ‚îÄ‚îÄ‚îÄ –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def choose_device() -> str:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (CPU/GPU)."""
    print("\n" + "="*70)
    print("‚öôÔ∏è  –í–´–ë–û–† –£–°–¢–†–û–ô–°–¢–í–ê –û–ë–†–ê–ë–û–¢–ö–ò")
    print("="*70)
    
    has_gpu = torch.cuda.is_available()
    print(f"\n–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:")
    print(f"  GPU –¥–æ—Å—Ç—É–ø–Ω–∞: {'‚úÖ –î–∞' if has_gpu else '‚ùå –ù–µ—Ç'}")
    if has_gpu:
        print(f"  –ú–æ–¥–µ–ª—å GPU: {torch.cuda.get_device_name(0)}")
    
    print(f"\n–û–ø—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print(f"  1Ô∏è‚É£  GPU (–±—ã—Å—Ç—Ä–µ–µ, —Ç—Ä–µ–±—É–µ—Ç NVIDIA —Å CUDA)")
    print(f"  2Ô∏è‚É£  CPU (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ)")
    print(f"  3Ô∏è‚É£  –ê–≤—Ç–æ (–≤—ã–±—Ä–∞—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)")
    
    choice = input(f"\n–í—ã–±–µ—Ä–∏—Ç–µ (1-3) [–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3]: ").strip() or "3"
    
    device_map = {
        "1": "gpu",
        "2": "cpu",
        "3": "auto"
    }
    
    device_choice = device_map.get(choice, "auto")
    init_device(device_choice)
    
    print(f"\n‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {DEVICE}\n")
    return str(DEVICE)


def random_distortion(tensor: torch.Tensor) -> torch.Tensor:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∫ —Ç–µ–Ω–∑–æ—Ä—É –¥–ª—è diversify –∞—Ç–∞–∫."""
    t = tensor.clone()
    
    if np.random.rand() > 0.5:
        t = t + torch.randn_like(t) * 0.008
    
    if np.random.rand() > 0.6:
        brightness_factor = 1 + 0.08 * (torch.rand(1, device=DEVICE).item() - 0.5) * 2
        t = transforms.functional.adjust_brightness(t, brightness_factor)
        
        contrast_factor = 1 + 0.08 * (torch.rand(1, device=DEVICE).item() - 0.5) * 2
        t = transforms.functional.adjust_contrast(t, contrast_factor)
    
    return t


# ‚îÄ‚îÄ‚îÄ‚îÄ –ö–õ–ê–°–° –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò –í–ò–î–ï–û ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
class VideoProcessor:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º adversarial noise."""
    
    def __init__(self, epsilon: float = CONFIG["epsilon_video"], 
                 num_eot: int = CONFIG["num_eot_transforms"]):
        if _model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å ResNet18 –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        self.model = _model
        self.preprocess = _preprocess
        self.epsilon = epsilon
        self.num_eot = num_eot
        self.device = DEVICE
    
    def add_imperceptible_video_noise(self, frame_bgr: np.ndarray, strength_mult: float = 1.0) -> np.ndarray:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–≤–∏–¥–∏–º—ã–π adversarial —à—É–º –∫ –∫–∞–¥—Ä—É –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞."""
        try:
            original_h, original_w = frame_bgr.shape[:2]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB float32 [0, 1]
            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]
            frame_rgb = np.clip(frame_rgb, 0.0, 1.0)
            
            # –°–æ–∑–¥–∞—ë–º tensor –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (C, H, W) - –°–†–ê–ó–£ –ù–ê GPU
            frame_tensor_orig = torch.from_numpy(frame_rgb.copy()).permute(2, 0, 1).float().to(self.device)
            
            # Resize –î–õ–Ø –ú–û–î–ï–õ–ò —Ç–æ–ª—å–∫–æ (224x224)
            frame_224 = torch.nn.functional.interpolate(
                frame_tensor_orig.unsqueeze(0),
                size=(224, 224),
                mode='bicubic',
                align_corners=False
            ).squeeze(0)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è ResNet
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(self.device)
            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(self.device)
            
            input_tensor = ((frame_224 - mean) / std).unsqueeze(0).to(self.device)
            
            total_grad = torch.zeros_like(input_tensor)
            
            # Ensemble of Transformations (EOT) –¥–ª—è robustness
            for _ in range(self.num_eot):
                distorted = random_distortion(input_tensor.detach().clone())
                distorted.requires_grad_(True)
                
                with torch.enable_grad():
                    out = self.model(distorted)
                    label = out.argmax(dim=1)
                    # –£–°–ò–õ–ï–ù–ù–ê–Ø loss —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±–æ–ª–µ–µ —Å–∏–ª—å–Ω–æ–≥–æ —à—É–º–∞
                    loss = F.cross_entropy(out, label) * 3.0
                    
                    self.model.zero_grad()
                    loss.backward()
                    
                    if distorted.grad is not None:
                        total_grad += distorted.grad.detach().clone()
            
            # –ï—Å–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç –Ω—É–ª–µ–≤–æ–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä
            if total_grad.abs().sum() == 0:
                logger.debug("–ù—É–ª–µ–≤–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç, –∫–∞–¥—Ä –Ω–µ –∏–∑–º–µ–Ω—ë–Ω")
                return frame_bgr
            
            avg_grad = total_grad / self.num_eot
            
            # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            grad_interp = torch.nn.functional.interpolate(
                avg_grad,
                size=(original_h, original_w),
                mode='bilinear',
                align_corners=False
            )
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π tensor –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è perturbation
            frame_tensor_orig_norm = ((frame_tensor_orig - mean) / std).unsqueeze(0).to(self.device)
            
            # FGSM –∞—Ç–∞–∫–∞ —Å –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ –∏ –º–Ω–æ–∂–∏—Ç–µ–ª–µ–º —Å–∏–ª—ã
            epsilon_effective = self.epsilon * strength_mult
            perturbed = frame_tensor_orig_norm + epsilon_effective * grad_interp.sign()
            
            # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            perturbed_denorm = perturbed * std + mean
            perturbed_denorm = torch.clamp(perturbed_denorm, 0, 1)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy (H, W, C) —Å –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            perturbed_float = perturbed_denorm.squeeze(0).permute(1, 2, 0).cpu().numpy()
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –ø–µ—Ä–µ–¥ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º
            perturbed_float = np.clip(perturbed_float, 0.0, 1.0)
            perturbed_rgb = (perturbed_float * 255.0).astype(np.uint8)
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
            perturbed_rgb = np.clip(perturbed_rgb, 0, 255)
            
            # RGB -> BGR
            perturbed_bgr = cv2.cvtColor(perturbed_rgb, cv2.COLOR_RGB2BGR)
            
            # –û—á–∏—â–∞–µ–º GPU –ø–∞–º—è—Ç—å
            del input_tensor, distorted, total_grad, avg_grad, grad_interp, frame_tensor_orig_norm, perturbed, perturbed_denorm
            torch.cuda.empty_cache()
            
            return perturbed_bgr
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤–∏–¥–µ–æ-—à—É–º–∞: {e}\n{traceback.format_exc()}")
            return frame_bgr
    
    def process_video(self, input_path: str, start_frame: int, end_frame: int, 
                     every_n_frames: int, video_strength_mult: float = 1.0,
                     should_cancel_fn=None) -> Tuple[str, int]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ, –¥–æ–±–∞–≤–ª—è—è —à—É–º –∫ –Ω—É–∂–Ω—ã–º –∫–∞–¥—Ä–∞–º.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–ø—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–ø–∫–µ, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤)
        """
        base = Path(input_path).stem
        input_dir = Path(input_path).parent
        temp_folder = input_dir / f"{base}{CONFIG['temp_folder_prefix']}{every_n_frames}f"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {input_path}")
        
        try:
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            if total_frames == 0 or fps == 0:
                raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ")
            
            # –ü—Ä–∏–≤–æ–¥–∏–º —Ä–∞–∑–º–µ—Ä –∫ —á—ë—Ç–Ω—ã–º —á–∏—Å–ª–∞–º (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ codec)
            w = w - (w % 2)
            h = h - (h % 2)
            
            logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ: {total_frames} –∫–∞–¥—Ä–æ–≤ @ {fps}fps, {w}x{h}")
            
            # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
            if temp_folder.exists():
                shutil.rmtree(temp_folder)
            temp_folder.mkdir(exist_ok=True)
            
            frame_idx = 0
            noisy_frames = 0
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤ —Å progress bar
            pbar = tqdm(total=total_frames, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ", unit="–∫–∞–¥—Ä")
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–º–µ–Ω—ã –∑–∞–¥–∞—á–∏
                if should_cancel_fn and should_cancel_fn():
                    logger.info("–û—Ç–º–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ")
                    pbar.close()
                    return str(temp_folder), noisy_frames
                
                frame_idx += 1
                frame = cv2.resize(frame, (w, h))
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —à—É–º —Ç–æ–ª—å–∫–æ –∫ –Ω—É–∂–Ω—ã–º –∫–∞–¥—Ä–∞–º
                if start_frame <= frame_idx <= end_frame and frame_idx % every_n_frames == 0:
                    try:
                        perturbed = self.add_imperceptible_video_noise(frame, video_strength_mult)
                        cv2.imwrite(str(temp_folder / f"frame_{frame_idx:06d}.png"), perturbed)
                        noisy_frames += 1
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞ {frame_idx}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Ä–∏–≥–∏–Ω–∞–ª: {e}")
                        cv2.imwrite(str(temp_folder / f"frame_{frame_idx:06d}.png"), frame)
                else:
                    cv2.imwrite(str(temp_folder / f"frame_{frame_idx:06d}.png"), frame)
                
                pbar.update(1)
            
            pbar.close()
            
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {frame_idx}, —Å —à—É–º–æ–º: {noisy_frames}")
            return str(temp_folder), noisy_frames
        
        finally:
            cap.release()


# ‚îÄ‚îÄ‚îÄ‚îÄ –ö–õ–ê–°–° –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò –ê–£–î–ò–û ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
class AudioProcessor:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–≤—É–∫–∞ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏—è."""
    
    @staticmethod
    def add_imperceptible_audio_noise(audio_path_in: str, audio_path_out: str, 
                                      level: str = "—Å–ª–∞–±—ã–π") -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–≤–∏–¥–∏–º—ã–π —à—É–º –∫ –∞—É–¥–∏–æ."""
        try:
            if level not in CONFIG["audio_levels"]:
                logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å '{level}', –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è '—Å–ª–∞–±—ã–π'")
                level = "—Å–ª–∞–±—ã–π"
            
            std = CONFIG["audio_levels"][level]
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            y, sr = librosa.load(audio_path_in, sr=16000, mono=True)
            
            if len(y) == 0:
                raise ValueError("–ê—É–¥–∏–æ-—Ç—Ä–µ–∫ –ø—É—Å—Ç")
            
            # –í—ã—á–∏—Å–ª—è–µ–º –æ–∫—Ä—É–∂–∞—é—â–∏–π —à—É–º (psychoacoustic masking)
            rms = librosa.feature.rms(y=y)[0]
            envelope = np.interp(
                np.linspace(0, len(rms)-1, len(y)), 
                np.arange(len(rms)), 
                rms
            )
            envelope = np.clip(envelope / (np.max(envelope) + 1e-8), 0.04, 1.0) ** 1.5
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —à—É–º
            t = np.arange(len(y), dtype=np.float32) / sr
            
            # –í—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–∏–Ω—É—Å (17 kHz) ‚Äî –Ω–µ—Å–ª—ã—à–∏–º–∞—è —á–∞—Å—Ç–æ—Ç–∞
            high_freq_mask = 0.0028 * np.sin(2 * np.pi * CONFIG["high_freq_base"] * t)
            
            # –ë–µ–ª—ã–π –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º
            noise_base = np.random.normal(0, std, len(y))
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å –ø—Å–∏—Ö–æ–∞–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–º –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            total_noise = (noise_base + high_freq_mask) * envelope
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —à—É–º –∫ –∞—É–¥–∏–æ
            adv_audio = y + total_noise
            adv_audio = np.clip(adv_audio, -0.999, 0.999)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            sf.write(audio_path_out, adv_audio, sr, subtype='PCM_16')
            logger.info(f"[AUDIO] Masking level '{level}' added -> {audio_path_out}")
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {e}\n{traceback.format_exc()}")
            raise


# ‚îÄ‚îÄ‚îÄ‚îÄ –§–£–ù–ö–¶–ò–ò –ò–ù–¢–ï–†–§–ï–ô–°–ê ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def choose_epsilon() -> float:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä epsilon (—Å–∏–ª—ã —à—É–º–∞) –¥–ª—è –≤–∏–¥–µ–æ."""
    print("\n" + "="*70)
    print("‚öôÔ∏è  –í–´–ë–û–† –°–ò–õ–´ –í–ò–î–ï–û-–®–£–ú–ê (epsilon)")
    print("="*70)
    
    recommendations = {
        "1": ("–û—á–µ–Ω—å —Å–ª–∞–±—ã–π (–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ –≤–∏–¥–Ω–æ)", 0.040),
        "2": ("–°–ª–∞–±—ã–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è —è—Ä–∫–∏—Ö –≤–∏–¥–µ–æ)", 0.070),
        "3": ("–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)", 0.120),
        "4": ("–°–∏–ª—å–Ω—ã–π (–≤–∏–¥–Ω–æ –Ω–µ–±–æ–ª—å—à–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤)", 0.180),
        "5": ("–ö–∞—Å—Ç–æ–º–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–≤–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é)", None),
    }
    
    print("\n–ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    for key, (desc, value) in recommendations.items():
        if value is not None:
            print(f"  {key}Ô∏è‚É£  {desc} (epsilon={value})")
        else:
            print(f"  {key}Ô∏è‚É£  {desc}")
    
    print(f"\n–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {CONFIG['epsilon_video']}")
    
    choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ (1-5) [–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3]: ").strip() or "3"
    
    if choice == "5":
        while True:
            try:
                custom = float(input("–í–≤–µ–¥–∏—Ç–µ –∫–∞—Å—Ç–æ–º–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ epsilon (0.01-0.5): "))
                if 0.01 <= custom <= 0.5:
                    print(f"‚úì –í—ã–±—Ä–∞–Ω–æ: epsilon={custom}")
                    return custom
                else:
                    print("‚ùå –ó–Ω–∞—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 0.01 –¥–æ 0.5")
            except ValueError:
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ!")
    elif choice in recommendations and recommendations[choice][1] is not None:
        desc, value = recommendations[choice]
        print(f"‚úì –í—ã–±—Ä–∞–Ω–æ: {desc} (epsilon={value})")
        return value
    else:
        return CONFIG["epsilon_video"]


def choose_strength_multiplier() -> float:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –º–Ω–æ–∂–∏—Ç–µ–ª—è —Å–∏–ª—ã —à—É–º–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    print("\n" + "="*70)
    print("‚öôÔ∏è  –í–´–ë–û–† –ú–ù–û–ñ–ò–¢–ï–õ–Ø –°–ò–õ–´ –®–£–ú–ê (strength_mult)")
    print("="*70)
    
    presets = {
        "1": ("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π (0.3x)", 0.3, "–î–ª—è –æ—á–µ–Ω—å —è—Ä–∫–∏—Ö –≤–∏–¥–µ–æ, –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã"),
        "2": ("–ù–∏–∑–∫–∏–π (0.6x)", 0.6, "–î–ª—è —è—Ä–∫–∏—Ö –≤–∏–¥–µ–æ, —Å–ª–∞–±–∞—è –∑–∞—â–∏—Ç–∞"),
        "3": ("–°—Ä–µ–¥–Ω–∏–π (1.0x)", 1.0, "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)"),
        "4": ("–í—ã—Å–æ–∫–∏–π (1.4x)", 1.4, "–î–ª—è –æ–±—ã—á–Ω—ã—Ö –≤–∏–¥–µ–æ, —Ö–æ—Ä–æ—à–∞—è –∑–∞—â–∏—Ç–∞"),
        "5": ("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π (1.8x)", 1.8, "–°–∏–ª—å–Ω—ã–π —à—É–º, —Ö–æ—Ä–æ—à–æ –≤–∏–¥–Ω–æ –Ω–µ–±–æ–ª—å—à–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã"),
        "6": ("–ö–∞—Å—Ç–æ–º–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", None, "–í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"),
    }
    
    print("\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–µsets:")
    for key, (name, value, desc) in presets.items():
        if value is not None:
            print(f"  {key}Ô∏è‚É£  {name}")
            print(f"       ‚îî‚îÄ {desc}")
        else:
            print(f"  {key}Ô∏è‚É£  {name}")
    
    choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ (1-6) [–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3]: ").strip() or "3"
    
    if choice == "6":
        while True:
            try:
                custom = float(input("–í–≤–µ–¥–∏—Ç–µ –∫–∞—Å—Ç–æ–º–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0.1-2.0): "))
                if 0.1 <= custom <= 2.0:
                    print(f"‚úì –í—ã–±—Ä–∞–Ω–æ: strength_mult={custom}")
                    return custom
                else:
                    print("‚ùå –ó–Ω–∞—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 0.1 –¥–æ 2.0")
            except ValueError:
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ!")
    elif choice in presets and presets[choice][1] is not None:
        name, value, desc = presets[choice]
        print(f"‚úì –í—ã–±—Ä–∞–Ω–æ: {name}")
        return value
    else:
        return 1.0


def list_video_files() -> list:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤ –≤ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ —Å –∞–±—Å–æ–ª—é—Ç–Ω—ã–º–∏ –ø—É—Ç—è–º–∏."""
    current = Path('.').resolve()
    videos = [
        str(f.resolve()) for f in current.iterdir() 
        if f.is_file() and f.suffix.lower() in CONFIG["supported_video"]
        and not f.name.endswith('_protected.mp4')
        and not CONFIG['temp_folder_prefix'] in f.name
    ]
    return sorted(videos)


def choose_video() -> Optional[str]:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞."""
    videos = list_video_files()
    if not videos:
        logger.error("–í —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ –ù–ï–¢ –≤–∏–¥–µ–æ-—Ñ–∞–π–ª–æ–≤!")
        return None
    
    logger.info("\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∏–¥–µ–æ –≤ –ø–∞–ø–∫–µ:")
    logger.info("-" * 70)
    for i, v in enumerate(videos, 1):
        logger.info(f"{i:2d} | {v}")
    logger.info("-" * 70)
    
    while True:
        try:
            num = input("–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –≤–∏–¥–µ–æ (0 = –≤—ã—Ö–æ–¥): ").strip()
            if num == "0":
                return None
            idx = int(num) - 1
            if 0 <= idx < len(videos):
                return videos[idx]
            logger.warning(f"–í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ {len(videos)}")
        except ValueError:
            logger.warning("–í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ!")
        except KeyboardInterrupt:
            return None


def choose_settings(total_frames: int) -> Tuple[int, int, Optional[str], int, float, float]:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (start_frame, end_frame, audio_level, every_n, video_strength_mult, epsilon)
    """
    print("\n" + "="*70)
    print("‚öôÔ∏è  –ù–ê–°–¢–†–û–ô–ö–ò –û–ë–†–ê–ë–û–¢–ö–ò –í–ò–î–ï–û")
    print("="*70)
    print(f"\n–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
    print(f"  üìπ –í–∏–¥–µ–æ —Å–æ–¥–µ—Ä–∂–∏—Ç {total_frames} –∫–∞–¥—Ä–æ–≤")
    print(f"  ‚è±Ô∏è  –ü—Ä–∏–º–µ—Ä–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_frames / 30:.1f} —Å–µ–∫ (–ø—Ä–∏ 30fps)\n")
    
    # 1. –í—ã–±–æ—Ä –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –∫–∞–¥—Ä–æ–≤
    print("[1/4] –î–ò–ê–ü–ê–ó–û–ù –û–ë–†–ê–ë–û–¢–ö–ò")
    print("-" * 70)
    print("1Ô∏è‚É£  –ü—Ä–∏–º–µ–Ω–∏—Ç—å —à—É–º –∫–æ –í–°–ï–ú–£ –≤–∏–¥–µ–æ")
    print("2Ô∏è‚É£  –í—ã–±—Ä–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω (–æ—Ç –∫–∞–¥—Ä–∞ X –¥–æ –∫–∞–¥—Ä–∞ Y)")
    
    choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ (1 –∏–ª–∏ 2) [–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1]: ").strip() or "1"
    
    start_frame = 1
    end_frame = total_frames
    
    if choice == "2":
        while True:
            try:
                start = int(input(f"  –ù–∞—á–∞–ª–æ (–æ—Ç 1 –¥–æ {total_frames}): "))
                end = int(input(f"  –ö–æ–Ω–µ—Ü (–æ—Ç {start} –¥–æ {total_frames}): "))
                if 1 <= start <= end <= total_frames:
                    start_frame = start
                    end_frame = end
                    print(f"  ‚úì –í—ã–±—Ä–∞–Ω–æ: –∫–∞–¥—Ä—ã {start_frame}‚Äì{end_frame}")
                    break
                else:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 1‚Äì{total_frames}")
            except ValueError:
                print("  ‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–∞!")
    else:
        print(f"  ‚úì –í—ã–±—Ä–∞–Ω–æ: –∫–∞–¥—Ä—ã 1‚Äì{total_frames} (–≤—Å–µ –≤–∏–¥–µ–æ)")
    
    # 2. –í—ã–±–æ—Ä —Å–∏–ª—ã –≤–∏–¥–µ–æ-—à—É–º–∞ (epsilon)
    print("\n[2/4] –°–ò–õ–ê –í–ò–î–ï–û-–®–£–ú–ê")
    print("-" * 70)
    epsilon = choose_epsilon()
    
    # 3. –í—ã–±–æ—Ä –º–Ω–æ–∂–∏—Ç–µ–ª—è —Å–∏–ª—ã (strength_mult)
    print("\n[3/4] –ú–ù–û–ñ–ò–¢–ï–õ–¨ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ô –°–ò–õ–´")
    print("-" * 70)
    video_strength_mult = choose_strength_multiplier()
    
    # 4. –ß–∞—Å—Ç–æ—Ç–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —à—É–º–∞
    print("\n[4/4] –ß–ê–°–¢–û–¢–ê –ü–†–ò–ú–ï–ù–ï–ù–ò–Ø –®–£–ú–ê")
    print("-" * 70)
    print("1Ô∏è‚É£  –ö–∞–∂–¥—ã–π –∫–∞–¥—Ä (–ª—É—á—à–µ –≤—Å–µ–≥–æ, –±–µ–∑ –º–µ—Ä—Ü–∞–Ω–∏—è)")
    print("2Ô∏è‚É£  –ö–∞–∂–¥—ã–π 5-–π –∫–∞–¥—Ä (–±—ã—Å—Ç—Ä–µ–µ, –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ—Ä—Ü–∞–Ω–∏–µ)")
    print("3Ô∏è‚É£  –ö–∞–∂–¥—ã–π 10-–π –∫–∞–¥—Ä (—Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)")
    
    freq_choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ (1-3) [–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1]: ").strip() or "1"
    every_n = 1 if freq_choice == "1" else 5 if freq_choice == "2" else 10
    print(f"  ‚úì –í—ã–±—Ä–∞–Ω–æ: —à—É–º –∫–∞–∂–¥—ã–µ {every_n} –∫–∞–¥—Ä–æ–≤")
    
    # –ê—É–¥–∏–æ-–º–∞—Å–∫–∏—Ä–æ–≤–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞)
    print("\n" + "="*70)
    print("üîä –ê–£–î–ò–û-–ú–ê–°–ö–ò–†–û–í–ö–ê (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞)")
    print("="*70)
    print("\n–ó–∞–º–µ—á–∞–Ω–∏–µ: —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å—Ç–∞–≤–∏—Ç—å –ë–ï–ó –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏ (–ø—Ä–æ–ø—É—Å—Ç–∏ —ç—Ç—É —á–∞—Å—Ç—å)")
    print("\n1Ô∏è‚É£  –ë–ï–ó –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏ –∞—É–¥–∏–æ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
    print("2Ô∏è‚É£  –ü—Ä–∏–º–µ–Ω–∏—Ç—å –º–∞—Å–∫–∏—Ä–æ–≤–∫—É (—Å–ª–∞–±—É—é)")
    print("3Ô∏è‚É£  –ü—Ä–∏–º–µ–Ω–∏—Ç—å –º–∞—Å–∫–∏—Ä–æ–≤–∫—É (—Å—Ä–µ–¥–Ω—é—é)")
    print("4Ô∏è‚É£  –ü—Ä–∏–º–µ–Ω–∏—Ç—å –º–∞—Å–∫–∏—Ä–æ–≤–∫—É (—Å–∏–ª—å–Ω—É—é)")
    
    audio_choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ (1-4) [–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1]: ").strip() or "1"
    
    audio_level = None
    if audio_choice == "2":
        audio_level = "—Å–ª–∞–±—ã–π"
        print(f"  ‚úì –í—ã–±—Ä–∞–Ω–æ: —Å–ª–∞–±–æ–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ")
    elif audio_choice == "3":
        audio_level = "—Å—Ä–µ–¥–Ω–∏–π"
        print(f"  ‚úì –í—ã–±—Ä–∞–Ω–æ: —Å—Ä–µ–¥–Ω–µ–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ")
    elif audio_choice == "4":
        audio_level = "—Å–∏–ª—å–Ω—ã–π"
        print(f"  ‚úì –í—ã–±—Ä–∞–Ω–æ: —Å–∏–ª—å–Ω–æ–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ")
    else:
        print(f"  ‚úì –í—ã–±—Ä–∞–Ω–æ: –±–µ–∑ –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏ (–∞—É–¥–∏–æ –Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è)")
    
    # –ò—Ç–æ–≥–æ–≤–æ–µ —Ä–µ–∑—é–º–µ
    print("\n" + "="*70)
    print("üìã –ò–¢–û–ì–û–í–´–ï –ù–ê–°–¢–†–û–ô–ö–ò")
    print("="*70)
    print(f"  –î–∏–∞–ø–∞–∑–æ–Ω: –∫–∞–¥—Ä—ã {start_frame}‚Äì{end_frame}")
    print(f"  Epsilon (—Å–∏–ª–∞ —à—É–º–∞): {epsilon}")
    print(f"  –ú–Ω–æ–∂–∏—Ç–µ–ª—å: {video_strength_mult}x")
    print(f"  –ß–∞—Å—Ç–æ—Ç–∞: –∫–∞–∂–¥—ã–µ {every_n} –∫–∞–¥—Ä–æ–≤")
    print(f"  –ê—É–¥–∏–æ: {'–±–µ–∑ –º–∞—Å–∫–∏—Ä–æ–≤–∫–∏' if audio_level is None else f'–º–∞—Å–∫–∏—Ä–æ–≤–∫–∞ ({audio_level})'}")
    print("="*70 + "\n")
    
    return start_frame, end_frame, audio_level, every_n, video_strength_mult, epsilon


def extract_audio(input_path: str, output_path: str) -> None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é ffmpeg (–±–µ–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)."""
    try:
        result = subprocess.run([
            CONFIG["ffmpeg_path"], "-y", "-i", input_path,
            "-vn", "-acodec", "pcm_s16le", "-ar", "16000",
            "-map_metadata", "-1",  # –£–¥–∞–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∞—É–¥–∏–æ
            output_path
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        if result.returncode != 0:
            raise RuntimeError(f"FFmpeg –æ—à–∏–±–∫–∞: {result.stderr}")
        
        logger.info(f"[AUDIO] Extracted -> {output_path}")
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤extraction –∞—É–¥–∏–æ: {e}")
        raise


def check_gpu_encoder() -> str:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU –∫–æ–¥–µ–∫–æ–≤ NVIDIA –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π."""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ GPU –∫–æ–¥–µ–∫–∏
        encoders_check = subprocess.run(
            [CONFIG["ffmpeg_path"], "-codecs"],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        
        output = encoders_check.stdout
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º HEVC GPU –∫–æ–¥–µ–∫ (–ª—É—á—à–µ –≤—Å–µ–≥–æ)
        if "hevc_nvenc" in output:
            logger.info("[GPU] Using encoder: HEVC NVENC (fastest)")
            return "hevc_nvenc"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º H.264 GPU –∫–æ–¥–µ–∫
        if "h264_nvenc" in output:
            logger.info("[GPU] Using encoder: H.264 NVENC")
            return "h264_nvenc"
        
        # Fallback –Ω–∞ CPU –∫–æ–¥–µ–∫
        logger.warning("[WARN] GPU codecs unavailable, using CPU codec (slower)")
        return "libx264"
    
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ GPU –∫–æ–¥–µ–∫–æ–≤: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
        return "libx264"


def assemble_video(temp_folder: str, audio_path: str, fps: float, output_path: str, use_gpu: bool = True) -> None:
    """–°–æ–±–∏—Ä–∞–µ—Ç –≤–∏–¥–µ–æ –∏–∑ –∫–∞–¥—Ä–æ–≤ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –∞—É–¥–∏–æ –∏ —É–¥–∞–ª–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
    try:
        # –í—ã–±–∏—Ä–∞–µ–º –∫–æ–¥–µ–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–ª–∏—á–∏—è GPU
        if use_gpu:
            encoder = check_gpu_encoder()
        else:
            encoder = "libx264"
            logger.info("üì∫ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU –∫–æ–¥–µ–∫: libx264")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∫–æ–¥–µ–∫–∞
        if encoder in ["hevc_nvenc", "h264_nvenc"]:
            # GPU –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (NVIDIA NVENC)
            video_codec_params = [
                "-c:v", encoder,
                "-pix_fmt", "yuv420p",  # –í–ê–ñ–ù–û: —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –ø–∏–∫—Å–µ–ª–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                "-rc", "vbr",  # Variable bitrate –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                "-cq", "23",   # Quality level (0-51, –Ω–∏–∂–µ = –ª—É—á—à–µ)
                "-preset", "fast"  # fast/medium/slow
            ]
        else:
            # CPU –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
            video_codec_params = [
                "-c:v", encoder,
                "-pix_fmt", "yuv420p",
                "-preset", "fast"  # –ë—ã—Å—Ç—Ä–∞—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ CPU
            ]
        
        ffmpeg_cmd = [
            CONFIG["ffmpeg_path"], "-y",
            "-framerate", str(fps),
            "-i", str(Path(temp_folder) / "frame_%06d.png"),
            "-i", audio_path
        ] + video_codec_params + [
            "-c:a", "aac", "-b:a", "128k",
            "-shortest",
            "-map_metadata", "-1",  # –£–¥–∞–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            output_path
        ]
        
        result = subprocess.run(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        if result.returncode != 0:
            raise RuntimeError(f"FFmpeg –æ—à–∏–±–∫–∞: {result.stderr}")
        
        logger.info(f"[OK] Video assembled via {encoder} -> {output_path}")
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∫–∏ –≤–∏–¥–µ–æ: {e}")
        raise


def cleanup_temps(temp_folder: str, *temp_files: str) -> None:
    """–û—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã."""
    try:
        if Path(temp_folder).exists():
            shutil.rmtree(temp_folder)
            logger.info(f"–£–¥–∞–ª–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞: {temp_folder}")
        
        for tmp_file in temp_files:
            if Path(tmp_file).exists():
                Path(tmp_file).unlink()
        
        logger.info("–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã")
    
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {e}")


def strip_metadata(file_path: str) -> None:
    """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞."""
    try:
        temp_path = f"{file_path}.tmp.mp4"
        
        result = subprocess.run([
            CONFIG["ffmpeg_path"], "-y", "-i", file_path,
            "-c:v", "copy",
            "-c:a", "copy",
            "-map_metadata", "-1",
            temp_path
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        if result.returncode != 0:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {result.stderr}")
            if Path(temp_path).exists():
                Path(temp_path).unlink()
            return
        
        # –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –Ω–∞ –æ—á–∏—â–µ–Ω–Ω—ã–π
        Path(temp_path).replace(file_path)
        logger.info(f"[OK] Metadata removed from {file_path}")
    
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")


# ‚îÄ‚îÄ‚îÄ‚îÄ –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def process_imperceptible_protected_video(input_path: str) -> bool:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –∏–Ω–∞—á–µ.
    """
    try:
        base = Path(input_path).stem
        input_dir = Path(input_path).parent
        temp_folder = str(input_dir / f"{base}{CONFIG['temp_folder_prefix']}_frames")
        temp_audio_orig = str(input_dir / f"{base}_audio_orig.wav")
        temp_audio_adv = str(input_dir / f"{base}_audio_adv.wav")
        output_final = str(input_dir / f"{base}_protected.mp4")
        
        logger.info(f"\n{'='*70}")
        logger.info(f"–ó–∞–ø—É—Å–∫ –∑–∞—â–∏—Ç—ã –≤–∏–¥–µ–æ")
        logger.info(f"–§–∞–π–ª: {input_path}")
        logger.info(f"{'='*70}\n")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
        if not Path(input_path).exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {input_path}")
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        start_frame, end_frame, audio_level, every_n, video_strength_mult, epsilon = choose_settings(total_frames)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º epsilon
        logger.info("\n[1/3] –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ (–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ GPU)...")
        video_processor = VideoProcessor(epsilon=epsilon)
        temp_folder, noisy_frames = video_processor.process_video(
            input_path, start_frame, end_frame, every_n, video_strength_mult
        )
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ
        logger.info("\n[2/3] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ...")
        extract_audio(input_path, temp_audio_orig)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –º–∞—Å–∫–∏—Ä–æ–≤–∫–∞)
        audio_processor = AudioProcessor()
        if audio_level is not None:
            logger.info(f"     –ü—Ä–∏–º–µ–Ω—è—é –º–∞—Å–∫–∏—Ä–æ–≤–∫—É –∞—É–¥–∏–æ —É—Ä–æ–≤–Ω—è '{audio_level}'...")
            audio_processor.add_imperceptible_audio_noise(temp_audio_orig, temp_audio_adv, audio_level)
            final_audio = temp_audio_adv
        else:
            logger.info("     –ú–∞—Å–∫–∏—Ä–æ–≤–∫–∞ –∞—É–¥–∏–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ)")
            final_audio = temp_audio_orig
        
        # –°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ GPU
        logger.info("\n[3/3] –°–±–æ—Ä–∫–∞ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É...")
        assemble_video(temp_folder, final_audio, fps, output_final, use_gpu=True)
        
        # –û—á–∏—Å—Ç–∫–∞
        logger.info("\n–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
        cleanup_temps(temp_folder, temp_audio_orig, temp_audio_adv)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        logger.info("–£–¥–∞–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤–∏–¥–µ–æ...")
        strip_metadata(output_final)
        
        logger.info(f"\n{'='*70}")
        logger.info(f"[DONE] Complete! Processed {total_frames} frames, {noisy_frames} with noise")
        logger.info(f"[OK] Final file: {output_final}")
        logger.info(f"[OK] Parameters: epsilon={epsilon}, strength_mult={video_strength_mult}x")
        logger.info(f"{'='*70}\n")
        
        return True
    
    except Exception as e:
        logger.error(f"\n[CRITICAL] Error: {e}\n{traceback.format_exc()}")
        return False


# ‚îÄ‚îÄ‚îÄ‚îÄ –ì–õ–ê–í–ù–´–ô –¶–ò–ö–õ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def main():
    """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –ø—Ä–æ–≥—Ä–∞–º–º—ã."""
    logger.info("‚ïî" + "="*68 + "‚ïó")
    logger.info("‚ïë Imperceptible Protected Video Generator v2.0                         ‚ïë")
    logger.info("‚ïë –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –Ω–µ–∑–∞–º–µ—Ç–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç CV –∏ ASR                            ‚ïë")
    logger.info("‚ïö" + "="*68 + "‚ïù\n")
    
    # –í—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    choose_device()
    
    while True:
        try:
            selected = choose_video()
            if selected is None:
                logger.info("\n–í—ã—Ö–æ–¥...")
                break
            
            success = process_imperceptible_protected_video(selected)
            
            if success:
                # –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –≤–∏–¥–µ–æ
                check = input("\nüîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ? (y/n): ").lower().strip()
                if check == 'y':
                    # –ù–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    original_dir = Path(selected).parent
                    output_file = original_dir / f"{Path(selected).stem}_protected{Path(selected).suffix}"
                    
                    if output_file.exists():
                        print()
                        verify_metadata(str(output_file))
                        verify_video_changes(selected, str(output_file), frame_num=0)
                    else:
                        print(f"‚ùå –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {output_file}")
                
                again = input("\n–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –µ—â—ë –æ–¥–Ω–æ –≤–∏–¥–µ–æ? (y/n): ").lower().strip()
                if again != 'y':
                    logger.info("–°–ø–∞—Å–∏–±–æ –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ!")
                    break
            else:
                retry = input("–ü–æ–≤—Ç–æ—Ä–∏—Ç—å? (y/n): ").lower().strip()
                if retry != 'y':
                    break
        
        except KeyboardInterrupt:
            logger.info("\n\n–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
            break
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –≥–ª–∞–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}\n{traceback.format_exc()}")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ: {e}\n{traceback.format_exc()}")
        sys.exit(1)
